{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport imageio\nfrom os import listdir\nimport skimage.transform\nimport pickle\nimport sys, os\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom collections import defaultdict\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom sklearn.metrics import roc_auc_score\nimport torch.optim as optim\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:48:36.251784Z","iopub.execute_input":"2022-05-03T03:48:36.252127Z","iopub.status.idle":"2022-05-03T03:48:39.2451Z","shell.execute_reply.started":"2022-05-03T03:48:36.252038Z","shell.execute_reply":"2022-05-03T03:48:39.244339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_entry_path = '../input/data/Data_Entry_2017.csv'\nmeta_data = pd.read_csv(data_entry_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:48:39.246771Z","iopub.execute_input":"2022-05-03T03:48:39.247029Z","iopub.status.idle":"2022-05-03T03:48:39.479913Z","shell.execute_reply.started":"2022-05-03T03:48:39.246995Z","shell.execute_reply":"2022-05-03T03:48:39.47918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_labels(pic_id):\n    try:\n        labels =  meta_data.loc[meta_data[\"Image Index\"]==pic_id,\"Finding Labels\"]\n        return labels.tolist()[0].split(\"|\")\n    except:\n        return []","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:48:39.513325Z","iopub.execute_input":"2022-05-03T03:48:39.51364Z","iopub.status.idle":"2022-05-03T03:48:39.517842Z","shell.execute_reply.started":"2022-05-03T03:48:39.513607Z","shell.execute_reply":"2022-05-03T03:48:39.5172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y = []\nfile_name_test = []\ntrain_y = []\nfile_name_train = [] \nval_y = []\nfile_name_val = [] \ndirectory = ['../input/data/images_001/images','../input/data/images_002/images','../input/data/images_003/images','../input/data/images_004/images',\n            '../input/data/images_005/images','../input/data/images_006/images','../input/data/images_007/images','../input/data/images_008/images',\n            '../input/data/images_009/images','../input/data/images_010/images','../input/data/images_011/images','../input/data/images_012/images']\ny=0\nfor i in directory:\n    for filename in os.listdir(i):\n        image_path = os.path.join(i,filename)\n        if len(get_labels(filename))!=0 and y<420:\n            test_y.append(get_labels(filename))\n            file_name_test.append(image_path)\n            y=y+1\n        elif len(get_labels(filename))!=0 and y<100000:\n            train_y.append(get_labels(filename))\n            file_name_train.append(image_path)\n            y=y+1\n        else:\n            val_y.append(get_labels(filename))\n            file_name_val.append(image_path)\n            y=y+1\n        if y%3000==0:\n            print(y)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T07:20:39.886022Z","iopub.execute_input":"2022-04-29T07:20:39.886839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = MultiLabelBinarizer()\nencoder.fit(train_y+test_y+val_y)\ntrain_y_onehot = encoder.transform(train_y)\ntest_y_onehot = encoder.transform(test_y)\nval_y_onehot = encoder.transform(val_y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.classes_","metadata":{"execution":{"iopub.status.busy":"2022-04-25T16:48:00.398347Z","iopub.execute_input":"2022-04-25T16:48:00.398611Z","iopub.status.idle":"2022-04-25T16:48:00.403436Z","shell.execute_reply.started":"2022-04-25T16:48:00.398582Z","shell.execute_reply":"2022-04-25T16:48:00.40272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_weight_pos_train = (len(train_y_onehot)-(train_y_onehot).sum(axis=0))/len(train_y_onehot)\nlabel_weight_neg_train = (train_y_onehot.sum(axis=0))/len(train_y_onehot)\nlabel_weight_pos_test = (len(test_y_onehot)-(test_y_onehot).sum(axis=0))/len(test_y_onehot)\nlabel_weight_neg_test = (test_y_onehot.sum(axis=0))/len(test_y_onehot)\nlabel_weight_pos_val = (len(val_y_onehot)-(val_y_onehot).sum(axis=0))/len(val_y_onehot)\nlabel_weight_neg_val = (val_y_onehot.sum(axis=0))/len(val_y_onehot)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./' + \"/train_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(train_y_onehot, f)\nwith open('./' + \"/test_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(test_y_onehot, f)\nwith open('./' + \"/val_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(val_y_onehot, f)\nwith open('./' + \"/train_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_train, f)\nwith open('./' + \"/test_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_test, f)\nwith open('./' + \"/val_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_val, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T05:14:32.303579Z","iopub.execute_input":"2022-05-01T05:14:32.303927Z","iopub.status.idle":"2022-05-01T05:14:32.62478Z","shell.execute_reply.started":"2022-05-01T05:14:32.303889Z","shell.execute_reply":"2022-05-01T05:14:32.622626Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/pickles/'\ndata_path1 = '../input/onehot/'\nwith open(data_path1 + \"val_y_onehot.pkl\", \"rb\") as f:\n                val_y = pickle.load(f)\nwith open(data_path1 + \"train_y_onehot.pkl\", \"rb\") as f:\n                train_y = pickle.load(f)\nwith open(data_path1 + \"test_y_onehot.pkl\", \"rb\") as f:\n                test_y = pickle.load(f)\nwith open(data_path + \"train_filename.pkl\", \"rb\") as f:\n                file_name_train = pickle.load(f)\nwith open(data_path + \"test_filename.pkl\", \"rb\") as f:\n                file_name_test = pickle.load(f)\nwith open(data_path + \"val_filename.pkl\", \"rb\") as f:\n                file_name_val = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:48:47.161241Z","iopub.execute_input":"2022-05-03T03:48:47.161516Z","iopub.status.idle":"2022-05-03T03:48:47.391207Z","shell.execute_reply.started":"2022-05-03T03:48:47.161485Z","shell.execute_reply":"2022-05-03T03:48:47.390468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ChestXrayDataSet(Dataset):\n    def __init__(self, train_or_valid = \"train\", transform=None):\n\n        data_path = './'\n        self.train_or_valid = train_or_valid\n        if train_or_valid == \"train\":\n            self.X = np.uint8(np.load(data_path + \"train_X_small.npy\")*255*255)\n            with open(data_path + \"train_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            #sub_bool = (self.y.sum(axis=1)!=0)\n            #self.y = self.y[sub_bool,:]\n            #self.X = self.X[sub_bool,:]\n            with open( \"../input/onehot/train_y_onehot.pkl\", \"rb\") as f:\n                a = pickle.load(f)\n        elif train_or_valid == \"valid\":\n            self.X = np.uint8(np.load(data_path + \"valid_X_small.npy\")*255*255)\n            with open(data_path + \"val_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            with open(\"../input/onehot/val_y_onehot.pkl\", \"rb\") as f:\n                a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n        else:\n            self.X = np.uint8(np.load(data_path + \"test_X_small.npy\")*255*255)\n            with open(data_path + \"test_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            with open(\"../input/onehot/test_y_onehot.pkl\", \"rb\") as f:\n                a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n         \n        self.label_weight_pos = len(a.T[13])/a.T[13].sum(axis=0)\n        self.label_weight_neg = len(a.T[13])/(len(a.T[13])-a.T[13].sum(axis=0))\n        self.transform = transform\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index: the index of item \n        Returns:\n            image and its labels\n        \"\"\"\n        current_X = np.tile(self.X[index],3) \n        label = self.y[index]\n        label_inverse = 1- label\n        weight = np.add((label_inverse * self.label_weight_neg),(label * self.label_weight_pos))\n        if self.transform is not None:\n            image = self.transform(current_X)\n        return image, torch.from_numpy(np.asarray(label)).type(torch.FloatTensor), torch.from_numpy(np.asarray(weight)).type(torch.FloatTensor)\n        #return image, torch.from_numpy(np.asarray(label)).type(torch.FloatTensor)\n    def __len__(self):\n        return len(self.y)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:48:50.336387Z","iopub.execute_input":"2022-05-03T03:48:50.336644Z","iopub.status.idle":"2022-05-03T03:48:50.355279Z","shell.execute_reply.started":"2022-05-03T03:48:50.336613Z","shell.execute_reply":"2022-05-03T03:48:50.3544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseNet121(nn.Module):\n    \"\"\"Model modified.\n    The architecture of our model is the same as standard DenseNet121\n    except the classifier layer which has an additional sigmoid function.\n    \"\"\"\n    def __init__(self, out_size):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n        num_ftrs = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n            nn.Linear(num_ftrs, out_size),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:48:57.038646Z","iopub.execute_input":"2022-05-03T03:48:57.038938Z","iopub.status.idle":"2022-05-03T03:48:57.044954Z","shell.execute_reply.started":"2022-05-03T03:48:57.038905Z","shell.execute_reply":"2022-05-03T03:48:57.044269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"../input/modele/model_epoch_pnuemonia_withweights_epochs1.pkl\", \"rb\") as f:\n                model = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:56:00.463401Z","iopub.execute_input":"2022-05-03T05:56:00.463688Z","iopub.status.idle":"2022-05-03T05:56:00.965939Z","shell.execute_reply.started":"2022-05-03T05:56:00.463657Z","shell.execute_reply":"2022-05-03T05:56:00.965164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cudnn.benchmark = True\nN_CLASSES = 1\nBATCH_SIZE = 16\n\n\t# initialize and load the model\n#model = DenseNet121(N_CLASSES).cuda()\n#model = torch.nn.DataParallel(model).cuda()\noptimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:26.023245Z","iopub.execute_input":"2022-05-03T03:49:26.024072Z","iopub.status.idle":"2022-05-03T03:49:26.032422Z","shell.execute_reply.started":"2022-05-03T03:49:26.024016Z","shell.execute_reply":"2022-05-03T03:49:26.031527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_util(index):\n    train_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_train[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        train_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_train)-1:\n            break\n    train_X = np.array(train_X)\n    np.save(os.path.join('./',\"train_X_small.npy\"), train_X)\n    train_y_ = train_y.T[13][index:i+1]\n    with open('./' + \"/train_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(train_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:28.208528Z","iopub.execute_input":"2022-05-03T03:49:28.208816Z","iopub.status.idle":"2022-05-03T03:49:28.217505Z","shell.execute_reply.started":"2022-05-03T03:49:28.208784Z","shell.execute_reply":"2022-05-03T03:49:28.216399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_util(index):\n    val_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_val[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        val_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_val)-1:\n            break\n    val_X = np.array(val_X)\n    np.save(os.path.join('./',\"valid_X_small.npy\"), val_X)\n    val_y_ = val_y.T[13][index:i+1]\n    with open('./' + \"/val_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(val_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:28.704348Z","iopub.execute_input":"2022-05-03T03:49:28.704598Z","iopub.status.idle":"2022-05-03T03:49:28.711837Z","shell.execute_reply.started":"2022-05-03T03:49:28.704569Z","shell.execute_reply":"2022-05-03T03:49:28.711032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_util(index):\n    test_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_test[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        test_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_test)-1:\n            break\n    print(len(test_X))\n    test_X = np.array(test_X)\n    np.save(os.path.join('./',\"test_X_small.npy\"), test_X)\n    test_y_ = test_y.T[13][index:i+1]\n    with open('./' + \"/test_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(test_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:29.103486Z","iopub.execute_input":"2022-05-03T03:49:29.103738Z","iopub.status.idle":"2022-05-03T03:49:29.114038Z","shell.execute_reply.started":"2022-05-03T03:49:29.103708Z","shell.execute_reply":"2022-05-03T03:49:29.113044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    for k in range(0,len(file_name_train),1000):\n        train_util(k)\n        train_dataset = ChestXrayDataSet(train_or_valid=\"train\",\n                                        transform=transforms.Compose([\n                                            transforms.ToPILImage(),\n                                            transforms.RandomCrop(224),\n                                            transforms.RandomHorizontalFlip(),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                            ]))\n        augment_img = []\n        augment_label = []\n        augment_weight = []\n\n#         for i in range(4):\n        for j in range(len(train_dataset)):\n            single_img, single_label, single_weight = train_dataset[j]\n            #single_img, single_label = train_dataset[j]\n            augment_img.append(single_img)\n            augment_label.append(single_label)\n            augment_weight.append(single_weight)\n\n        # shuffe data\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = torch.stack(augment_img)[perm_index]\n        augment_label = torch.stack(augment_label)[perm_index]\n        augment_weight = torch.stack(augment_weight)[perm_index]\n\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = augment_img[perm_index]\n        augment_label = augment_label[perm_index]\n        augment_weight = augment_weight[perm_index]\n\n        optimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))\n        total_length = len(augment_img)\n        for index in range(0, total_length , BATCH_SIZE):\n            if index+BATCH_SIZE >= total_length:\n                break\n    # zero the parameter gradients\n            optimizer.zero_grad()\n            inputs_sub = augment_img[index:index+BATCH_SIZE]\n            labels_sub = augment_label[index:index+BATCH_SIZE]\n            weights_sub = augment_weight[index:index+BATCH_SIZE]\n            inputs_sub, labels_sub = Variable(inputs_sub.cuda()), Variable(labels_sub.cuda())\n            weights_sub = Variable(weights_sub.cuda())\n\n    # forward + backward + optimize\n            outputs = model(inputs_sub)\n            criterion = nn.BCELoss()\n            loss = criterion(outputs, torch.reshape(labels_sub,(16,1)))\n            loss.backward()\n            optimizer.step()\n        print(k)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:29.535172Z","iopub.execute_input":"2022-05-03T03:49:29.535424Z","iopub.status.idle":"2022-05-03T03:49:29.547788Z","shell.execute_reply.started":"2022-05-03T03:49:29.535395Z","shell.execute_reply":"2022-05-03T03:49:29.54703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_val),1000):\n        val_util(k)\n        valid_dataset = ChestXrayDataSet(train_or_valid=\"valid\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        valid_loader = DataLoader(dataset=valid_dataset, batch_size=16, shuffle=False, num_workers=16)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target,weight) in enumerate(valid_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    \n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))\n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:29.891939Z","iopub.execute_input":"2022-05-03T03:49:29.892629Z","iopub.status.idle":"2022-05-03T03:49:29.904824Z","shell.execute_reply.started":"2022-05-03T03:49:29.892588Z","shell.execute_reply":"2022-05-03T03:49:29.903819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(file_name_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:30.875935Z","iopub.execute_input":"2022-05-03T03:49:30.876544Z","iopub.status.idle":"2022-05-03T03:49:30.884832Z","shell.execute_reply.started":"2022-05-03T03:49:30.876505Z","shell.execute_reply":"2022-05-03T03:49:30.884023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_test),1000):\n        test_util(k)\n        test_dataset = ChestXrayDataSet(train_or_valid=\"test\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False, num_workers=2)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target,weight) in enumerate(test_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))\n    \n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:33.363813Z","iopub.execute_input":"2022-05-03T03:49:33.364218Z","iopub.status.idle":"2022-05-03T03:49:33.376626Z","shell.execute_reply.started":"2022-05-03T03:49:33.364179Z","shell.execute_reply":"2022-05-03T03:49:33.375914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_AUCs(gt, pred):\n\t\n    AUROCs = []\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    gt_np = np.reshape(gt_np,(gt_np.shape[0],1))\n    print(gt_np.shape, pred_np.shape)\n    for i in range(N_CLASSES):\n        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return AUROCs\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:34.07792Z","iopub.execute_input":"2022-05-03T03:49:34.078528Z","iopub.status.idle":"2022-05-03T03:49:34.086205Z","shell.execute_reply.started":"2022-05-03T03:49:34.078489Z","shell.execute_reply":"2022-05-03T03:49:34.083472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=1\nfor i in range(epochs):\n    train()\n    model.eval()\n    avg_roc = val()\n    torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(2)+'_'+str(avg_roc)+'.pkl')\n    model.train()\n  ","metadata":{"execution":{"iopub.status.busy":"2022-05-03T03:49:35.537762Z","iopub.execute_input":"2022-05-03T03:49:35.538031Z","iopub.status.idle":"2022-05-03T05:53:42.464795Z","shell.execute_reply.started":"2022-05-03T03:49:35.538Z","shell.execute_reply":"2022-05-03T05:53:42.463895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(1)+'_'+str(AUROC_avg)+'.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:39:57.245726Z","iopub.execute_input":"2022-04-26T12:39:57.246301Z","iopub.status.idle":"2022-04-26T12:39:57.276397Z","shell.execute_reply.started":"2022-04-26T12:39:57.246261Z","shell.execute_reply":"2022-04-26T12:39:57.275428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./' + \"/model_epoch_pnuemotharax_withweights_epochs2.pkl\",\"wb\") as f:\n    pickle.dump(model, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:54:14.761926Z","iopub.execute_input":"2022-05-03T05:54:14.762699Z","iopub.status.idle":"2022-05-03T05:54:14.872019Z","shell.execute_reply.started":"2022-05-03T05:54:14.762658Z","shell.execute_reply":"2022-05-03T05:54:14.871265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:56:08.471701Z","iopub.execute_input":"2022-05-03T05:56:08.471953Z","iopub.status.idle":"2022-05-03T05:56:29.009064Z","shell.execute_reply.started":"2022-05-03T05:56:08.471925Z","shell.execute_reply":"2022-05-03T05:56:29.008253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}