{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport imageio\nfrom os import listdir\nimport skimage.transform\nimport pickle\nimport sys, os\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom collections import defaultdict\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom sklearn.metrics import roc_auc_score\nimport torch.optim as optim\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:57:15.023455Z","iopub.execute_input":"2022-05-02T10:57:15.024227Z","iopub.status.idle":"2022-05-02T10:57:17.856982Z","shell.execute_reply.started":"2022-05-02T10:57:15.02412Z","shell.execute_reply":"2022-05-02T10:57:17.85628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_entry_path = '../input/data/Data_Entry_2017.csv'\nmeta_data = pd.read_csv(data_entry_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:57:20.413022Z","iopub.execute_input":"2022-05-02T10:57:20.413569Z","iopub.status.idle":"2022-05-02T10:57:20.671682Z","shell.execute_reply.started":"2022-05-02T10:57:20.413533Z","shell.execute_reply":"2022-05-02T10:57:20.670949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_labels(pic_id):\n    try:\n        labels =  meta_data.loc[meta_data[\"Image Index\"]==pic_id,\"Finding Labels\"]\n        return labels.tolist()[0].split(\"|\")\n    except:\n        return []","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:57:20.77389Z","iopub.execute_input":"2022-05-02T10:57:20.774137Z","iopub.status.idle":"2022-05-02T10:57:20.778863Z","shell.execute_reply.started":"2022-05-02T10:57:20.77411Z","shell.execute_reply":"2022-05-02T10:57:20.777952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y = []\nfile_name_test = []\ntrain_y = []\nfile_name_train = [] \nval_y = []\nfile_name_val = [] \ndirectory = ['../input/data/images_001/images','../input/data/images_002/images','../input/data/images_003/images','../input/data/images_004/images',\n            '../input/data/images_005/images','../input/data/images_006/images','../input/data/images_007/images','../input/data/images_008/images',\n            '../input/data/images_009/images','../input/data/images_010/images','../input/data/images_011/images','../input/data/images_012/images']\ny=0\nfor i in directory:\n    for filename in os.listdir(i):\n        image_path = os.path.join(i,filename)\n        if len(get_labels(filename))!=0 and y<420:\n            test_y.append(get_labels(filename))\n            file_name_test.append(image_path)\n            y=y+1\n        elif len(get_labels(filename))!=0 and y<100000:\n            train_y.append(get_labels(filename))\n            file_name_train.append(image_path)\n            y=y+1\n        else:\n            val_y.append(get_labels(filename))\n            file_name_val.append(image_path)\n            y=y+1\n        if y%3000==0:\n            print(y)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:37:38.087307Z","iopub.execute_input":"2022-04-30T12:37:38.087815Z","iopub.status.idle":"2022-04-30T14:21:17.833893Z","shell.execute_reply.started":"2022-04-30T12:37:38.087777Z","shell.execute_reply":"2022-04-30T14:21:17.832953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = MultiLabelBinarizer()\nencoder.fit(train_y+test_y+val_y)\ntrain_y_onehot = encoder.transform(train_y)\ntest_y_onehot = encoder.transform(test_y)\nval_y_onehot = encoder.transform(val_y)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T14:21:17.835756Z","iopub.execute_input":"2022-04-30T14:21:17.836069Z","iopub.status.idle":"2022-04-30T14:21:17.995722Z","shell.execute_reply.started":"2022-04-30T14:21:17.836027Z","shell.execute_reply":"2022-04-30T14:21:17.995115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.classes_","metadata":{"execution":{"iopub.status.busy":"2022-04-30T14:44:55.356395Z","iopub.execute_input":"2022-04-30T14:44:55.356746Z","iopub.status.idle":"2022-04-30T14:44:55.366293Z","shell.execute_reply.started":"2022-04-30T14:44:55.356714Z","shell.execute_reply":"2022-04-30T14:44:55.365536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y_onehot = np.delete(train_y_onehot, [10],1) # delete \"No Finding\" column\nval_y_onehot = np.delete(val_y_onehot, [10],1)\ntest_y_onehot = np.delete(test_y_onehot,[10],1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T14:45:37.817882Z","iopub.execute_input":"2022-04-30T14:45:37.8182Z","iopub.status.idle":"2022-04-30T14:45:37.83309Z","shell.execute_reply.started":"2022-04-30T14:45:37.818169Z","shell.execute_reply":"2022-04-30T14:45:37.831889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y = train_y_onehot\nval_y = val_y_onehot\ntest_y = test_y_onehot\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T14:46:46.243414Z","iopub.execute_input":"2022-04-30T14:46:46.243695Z","iopub.status.idle":"2022-04-30T14:46:46.258146Z","shell.execute_reply.started":"2022-04-30T14:46:46.243666Z","shell.execute_reply":"2022-04-30T14:46:46.257547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_weight_pos_train = (len(train_y_onehot)-(train_y_onehot).sum(axis=0))/len(train_y_onehot)\nlabel_weight_neg_train = (train_y_onehot.sum(axis=0))/len(train_y_onehot)\nlabel_weight_pos_test = (len(test_y_onehot)-(test_y_onehot).sum(axis=0))/len(test_y_onehot)\nlabel_weight_neg_test = (test_y_onehot.sum(axis=0))/len(test_y_onehot)\nlabel_weight_pos_val = (len(val_y_onehot)-(val_y_onehot).sum(axis=0))/len(val_y_onehot)\nlabel_weight_neg_val = (val_y_onehot.sum(axis=0))/len(val_y_onehot)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./' + \"/train_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(train_y_onehot, f)\nwith open('./' + \"/test_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(test_y_onehot, f)\nwith open('./' + \"/val_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(val_y_onehot, f)\nwith open('./' + \"/train_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_train, f)\nwith open('./' + \"/test_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_test, f)\nwith open('./' + \"/val_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_val, f)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T14:47:42.751274Z","iopub.execute_input":"2022-04-30T14:47:42.75156Z","iopub.status.idle":"2022-04-30T14:47:42.804767Z","shell.execute_reply.started":"2022-04-30T14:47:42.751529Z","shell.execute_reply":"2022-04-30T14:47:42.80402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/pickles/'\ndata_path1 = '../input/onehot/'\nwith open(data_path1 + \"val_y_onehot.pkl\", \"rb\") as f:\n                val_y = pickle.load(f)\nwith open(data_path1 + \"train_y_onehot.pkl\", \"rb\") as f:\n                train_y = pickle.load(f)\nwith open(data_path1 + \"test_y_onehot.pkl\", \"rb\") as f:\n                test_y = pickle.load(f)\nwith open(data_path + \"train_filename.pkl\", \"rb\") as f:\n                file_name_train = pickle.load(f)\nwith open(data_path + \"test_filename.pkl\", \"rb\") as f:\n                file_name_test = pickle.load(f)\nwith open(data_path + \"val_filename.pkl\", \"rb\") as f:\n                file_name_val = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:57:26.827136Z","iopub.execute_input":"2022-05-02T10:57:26.827456Z","iopub.status.idle":"2022-05-02T10:57:27.13644Z","shell.execute_reply.started":"2022-05-02T10:57:26.827412Z","shell.execute_reply":"2022-05-02T10:57:27.135685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ChestXrayDataSet(Dataset):\n    def __init__(self, train_or_valid = \"train\", transform=None):\n\n        data_path = './'\n        self.train_or_valid = train_or_valid\n        if train_or_valid == \"train\":\n            self.X = np.uint8(np.load(data_path + \"train_X_small.npy\")*255*255)\n            with open(data_path + \"train_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            #sub_bool = (self.y.sum(axis=1)!=0)\n            #self.y = self.y[sub_bool,:]\n            #self.X = self.X[sub_bool,:]\n            with open( \"../input/onehot/train_y_onehot.pkl\", \"rb\") as f:\n                a = pickle.load(f)\n        elif train_or_valid == \"valid\":\n            self.X = np.uint8(np.load(data_path + \"valid_X_small.npy\")*255*255)\n            with open(data_path + \"val_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            with open(\"../input/onehot/val_y_onehot.pkl\", \"rb\") as f:\n                a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n        else:\n            self.X = np.uint8(np.load(data_path + \"test_X_small.npy\")*255*255)\n            with open(data_path + \"test_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            with open(\"../input/onehot/test_y_onehot.pkl\", \"rb\") as f:\n                a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n         \n        self.label_weight_pos = len(a)/a.sum(axis=0)\n        self.label_weight_neg = len(a)/(len(a)-a.sum(axis=0))\n        self.transform = transform\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index: the index of item \n        Returns:\n            image and its labels\n        \"\"\"\n        current_X = np.tile(self.X[index],3) \n        label = self.y[index]\n        label_inverse = 1- label\n        weight = np.add((label_inverse * self.label_weight_neg),(label * self.label_weight_pos))\n        if self.transform is not None:\n            image = self.transform(current_X)\n        return image, torch.from_numpy(label).type(torch.FloatTensor), torch.from_numpy(weight).type(torch.FloatTensor)\n    def __len__(self):\n        return len(self.y)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:57:28.828255Z","iopub.execute_input":"2022-05-02T10:57:28.828522Z","iopub.status.idle":"2022-05-02T10:57:28.84579Z","shell.execute_reply.started":"2022-05-02T10:57:28.828495Z","shell.execute_reply":"2022-05-02T10:57:28.845042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseNet121(nn.Module):\n    \"\"\"Model modified.\n    The architecture of our model is the same as standard DenseNet121\n    except the classifier layer which has an additional sigmoid function.\n    \"\"\"\n    def __init__(self, out_size):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n        num_ftrs = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n            nn.Linear(num_ftrs, out_size),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:57:29.285935Z","iopub.execute_input":"2022-05-02T10:57:29.286485Z","iopub.status.idle":"2022-05-02T10:57:29.292277Z","shell.execute_reply.started":"2022-05-02T10:57:29.286453Z","shell.execute_reply":"2022-05-02T10:57:29.291517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"../input/newmodel/model_epoch.pkl\", \"rb\") as f:\n                model = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:00:01.023352Z","iopub.execute_input":"2022-05-02T11:00:01.023669Z","iopub.status.idle":"2022-05-02T11:00:01.150577Z","shell.execute_reply.started":"2022-05-02T11:00:01.023638Z","shell.execute_reply":"2022-05-02T11:00:01.149872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cudnn.benchmark = True\nN_CLASSES = 15\nBATCH_SIZE = 16\n\n\t# initialize and load the model\nmodel = DenseNet121(N_CLASSES).cuda()\nmodel = torch.nn.DataParallel(model).cuda()\noptimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:57:32.617695Z","iopub.execute_input":"2022-05-02T10:57:32.617979Z","iopub.status.idle":"2022-05-02T10:57:36.43203Z","shell.execute_reply.started":"2022-05-02T10:57:32.61795Z","shell.execute_reply":"2022-05-02T10:57:36.431274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_util(index):\n    train_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_train[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        train_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_train)-1:\n            break\n    train_X = np.array(train_X)\n    np.save(os.path.join('./',\"train_X_small.npy\"), train_X)\n    train_y_ = train_y[index:i+1]\n    with open('./' + \"/train_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(train_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:59:42.100996Z","iopub.execute_input":"2022-05-02T10:59:42.10156Z","iopub.status.idle":"2022-05-02T10:59:42.111042Z","shell.execute_reply.started":"2022-05-02T10:59:42.101519Z","shell.execute_reply":"2022-05-02T10:59:42.109882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_util(index):\n    val_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_val[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        val_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_val)-1:\n            break\n    val_X = np.array(val_X)\n    np.save(os.path.join('./',\"valid_X_small.npy\"), val_X)\n    val_y_ = val_y[index:i+1]\n    with open('./' + \"/val_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(val_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:59:42.5802Z","iopub.execute_input":"2022-05-02T10:59:42.580733Z","iopub.status.idle":"2022-05-02T10:59:42.5876Z","shell.execute_reply.started":"2022-05-02T10:59:42.5807Z","shell.execute_reply":"2022-05-02T10:59:42.586757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_util(index):\n    test_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_test[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        test_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_test)-1:\n            break\n    print(len(test_X))\n    test_X = np.array(test_X)\n    np.save(os.path.join('./',\"test_X_small.npy\"), test_X)\n    test_y_ = test_y[index:i+1]\n    with open('./' + \"/test_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(test_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:59:43.496045Z","iopub.execute_input":"2022-05-02T10:59:43.496746Z","iopub.status.idle":"2022-05-02T10:59:43.504639Z","shell.execute_reply.started":"2022-05-02T10:59:43.496697Z","shell.execute_reply":"2022-05-02T10:59:43.503822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    for k in range(0,len(file_name_train),1000):\n        train_util(k)\n        train_dataset = ChestXrayDataSet(train_or_valid=\"train\",\n                                        transform=transforms.Compose([\n                                            transforms.ToPILImage(),\n                                            transforms.RandomCrop(224),\n                                            transforms.RandomHorizontalFlip(),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                            ]))\n        augment_img = []\n        augment_label = []\n        augment_weight = []\n\n        \n        for j in range(len(train_dataset)):\n            single_img, single_label, single_weight = train_dataset[j]\n            augment_img.append(single_img)\n            augment_label.append(single_label)\n            augment_weight.append(single_weight)\n\n        # shuffe data\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = torch.stack(augment_img)[perm_index]\n        augment_label = torch.stack(augment_label)[perm_index]\n        augment_weight = torch.stack(augment_weight)[perm_index]\n\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = augment_img[perm_index]\n        augment_label = augment_label[perm_index]\n        augment_weight = augment_weight[perm_index]\n\n        optimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))\n        total_length = len(augment_img)\n        for index in range(0, total_length , BATCH_SIZE):\n            if index+BATCH_SIZE >= total_length:\n                break\n    # zero the parameter gradients\n            optimizer.zero_grad()\n            inputs_sub = augment_img[index:index+BATCH_SIZE]\n            labels_sub = augment_label[index:index+BATCH_SIZE]\n            weights_sub = augment_weight[index:index+BATCH_SIZE]\n            inputs_sub, labels_sub = Variable(inputs_sub.cuda()), Variable(labels_sub.cuda())\n            weights_sub = Variable(weights_sub.cuda())\n\n    # forward + backward + optimize\n            outputs = model(inputs_sub)\n            criterion = nn.BCELoss()\n            loss = criterion(outputs, labels_sub)\n            loss.backward()\n            optimizer.step()\n        print(k)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:59:43.834658Z","iopub.execute_input":"2022-05-02T10:59:43.834868Z","iopub.status.idle":"2022-05-02T10:59:43.84745Z","shell.execute_reply.started":"2022-05-02T10:59:43.834843Z","shell.execute_reply":"2022-05-02T10:59:43.846411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_val),1000):\n        val_util(k)\n        valid_dataset = ChestXrayDataSet(train_or_valid=\"valid\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        valid_loader = DataLoader(dataset=valid_dataset, batch_size=16, shuffle=False, num_workers=16)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target, weight) in enumerate(valid_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))\n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:59:44.409787Z","iopub.execute_input":"2022-05-02T10:59:44.410413Z","iopub.status.idle":"2022-05-02T10:59:44.423019Z","shell.execute_reply.started":"2022-05-02T10:59:44.410375Z","shell.execute_reply":"2022-05-02T10:59:44.422245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_test),1000):\n        test_util(k)\n        test_dataset = ChestXrayDataSet(train_or_valid=\"test\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False, num_workers=2)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target, weight) in enumerate(test_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))\n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:59:44.716143Z","iopub.execute_input":"2022-05-02T10:59:44.716557Z","iopub.status.idle":"2022-05-02T10:59:44.728268Z","shell.execute_reply.started":"2022-05-02T10:59:44.716524Z","shell.execute_reply":"2022-05-02T10:59:44.727408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_AUCs(gt, pred):\n\t\n    AUROCs = []\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    for i in range(N_CLASSES):\n        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return AUROCs\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:59:45.033021Z","iopub.execute_input":"2022-05-02T10:59:45.033222Z","iopub.status.idle":"2022-05-02T10:59:45.03811Z","shell.execute_reply.started":"2022-05-02T10:59:45.033199Z","shell.execute_reply":"2022-05-02T10:59:45.037379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=2\nfor i in range(epochs):\n    train()\n    model.eval()\n    avg_roc = val()\n    torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(2)+'_'+str(avg_roc)+'.pkl')\n    model.train()\n  ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:11:06.395112Z","iopub.execute_input":"2022-05-02T11:11:06.395479Z","iopub.status.idle":"2022-05-02T15:22:12.861392Z","shell.execute_reply.started":"2022-05-02T11:11:06.395438Z","shell.execute_reply":"2022-05-02T15:22:12.860023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(1)+'_'+str(AUROC_avg)+'.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T09:16:13.788722Z","iopub.execute_input":"2022-04-30T09:16:13.789009Z","iopub.status.idle":"2022-04-30T09:16:13.841454Z","shell.execute_reply.started":"2022-04-30T09:16:13.788976Z","shell.execute_reply":"2022-04-30T09:16:13.840567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./' + \"/model_epoch4.pkl\",\"wb\") as f:\n    pickle.dump(model, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:34:45.234057Z","iopub.execute_input":"2022-05-02T15:34:45.234615Z","iopub.status.idle":"2022-05-02T15:34:45.353076Z","shell.execute_reply.started":"2022-05-02T15:34:45.234573Z","shell.execute_reply":"2022-05-02T15:34:45.352286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T15:34:58.447713Z","iopub.execute_input":"2022-05-02T15:34:58.448357Z","iopub.status.idle":"2022-05-02T15:35:23.331686Z","shell.execute_reply.started":"2022-05-02T15:34:58.448319Z","shell.execute_reply":"2022-05-02T15:35:23.330793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}