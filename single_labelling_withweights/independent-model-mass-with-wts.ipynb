{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport imageio\nfrom os import listdir\nimport skimage.transform\nimport pickle\nimport sys, os\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom collections import defaultdict\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom sklearn.metrics import roc_auc_score\nimport torch.optim as optim\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:12:21.969704Z","iopub.execute_input":"2022-05-02T19:12:21.970311Z","iopub.status.idle":"2022-05-02T19:12:25.100988Z","shell.execute_reply.started":"2022-05-02T19:12:21.970200Z","shell.execute_reply":"2022-05-02T19:12:25.100147Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_entry_path = '../input/data/Data_Entry_2017.csv'\nmeta_data = pd.read_csv(data_entry_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:06:13.679380Z","iopub.execute_input":"2022-05-02T09:06:13.679636Z","iopub.status.idle":"2022-05-02T09:06:13.920939Z","shell.execute_reply.started":"2022-05-02T09:06:13.679603Z","shell.execute_reply":"2022-05-02T09:06:13.920187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_labels(pic_id):\n    try:\n        labels =  meta_data.loc[meta_data[\"Image Index\"]==pic_id,\"Finding Labels\"]\n        return labels.tolist()[0].split(\"|\")\n    except:\n        return []","metadata":{"execution":{"iopub.status.busy":"2022-05-02T09:06:13.930481Z","iopub.execute_input":"2022-05-02T09:06:13.930692Z","iopub.status.idle":"2022-05-02T09:06:13.937583Z","shell.execute_reply.started":"2022-05-02T09:06:13.930667Z","shell.execute_reply":"2022-05-02T09:06:13.936805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y = []\nfile_name_test = []\ntrain_y = []\nfile_name_train = [] \nval_y = []\nfile_name_val = [] \ndirectory = ['../input/data/images_001/images','../input/data/images_002/images','../input/data/images_003/images','../input/data/images_004/images',\n            '../input/data/images_005/images','../input/data/images_006/images','../input/data/images_007/images','../input/data/images_008/images',\n            '../input/data/images_009/images','../input/data/images_010/images','../input/data/images_011/images','../input/data/images_012/images']\ny=0\nfor i in directory:\n    for filename in os.listdir(i):\n        image_path = os.path.join(i,filename)\n        if len(get_labels(filename))!=0 and y<420:\n            test_y.append(get_labels(filename))\n            file_name_test.append(image_path)\n            y=y+1\n        elif len(get_labels(filename))!=0 and y<100000:\n            train_y.append(get_labels(filename))\n            file_name_train.append(image_path)\n            y=y+1\n        else:\n            val_y.append(get_labels(filename))\n            file_name_val.append(image_path)\n            y=y+1\n        if y%3000==0:\n            print(y)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T07:20:39.886022Z","iopub.execute_input":"2022-04-29T07:20:39.886839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = MultiLabelBinarizer()\nencoder.fit(train_y+test_y+val_y)\ntrain_y_onehot = encoder.transform(train_y)\ntest_y_onehot = encoder.transform(test_y)\nval_y_onehot = encoder.transform(val_y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.classes_","metadata":{"execution":{"iopub.status.busy":"2022-04-25T16:48:00.398347Z","iopub.execute_input":"2022-04-25T16:48:00.398611Z","iopub.status.idle":"2022-04-25T16:48:00.403436Z","shell.execute_reply.started":"2022-04-25T16:48:00.398582Z","shell.execute_reply":"2022-04-25T16:48:00.40272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_weight_pos_train = (len(train_y_onehot)-(train_y_onehot).sum(axis=0))/len(train_y_onehot)\nlabel_weight_neg_train = (train_y_onehot.sum(axis=0))/len(train_y_onehot)\nlabel_weight_pos_test = (len(test_y_onehot)-(test_y_onehot).sum(axis=0))/len(test_y_onehot)\nlabel_weight_neg_test = (test_y_onehot.sum(axis=0))/len(test_y_onehot)\nlabel_weight_pos_val = (len(val_y_onehot)-(val_y_onehot).sum(axis=0))/len(val_y_onehot)\nlabel_weight_neg_val = (val_y_onehot.sum(axis=0))/len(val_y_onehot)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./' + \"/train_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(train_y_onehot, f)\nwith open('./' + \"/test_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(test_y_onehot, f)\nwith open('./' + \"/val_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(val_y_onehot, f)\nwith open('./' + \"/train_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_train, f)\nwith open('./' + \"/test_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_test, f)\nwith open('./' + \"/val_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_val, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T05:14:32.303579Z","iopub.execute_input":"2022-05-01T05:14:32.303927Z","iopub.status.idle":"2022-05-01T05:14:32.624780Z","shell.execute_reply.started":"2022-05-01T05:14:32.303889Z","shell.execute_reply":"2022-05-01T05:14:32.622626Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/pickles/'\ndata_path1 = '../input/pickles/'\nwith open(data_path1 + \"val_y_onehot.pkl\", \"rb\") as f:\n                val_y = pickle.load(f)\nwith open(data_path1 + \"train_y_onehot.pkl\", \"rb\") as f:\n                train_y = pickle.load(f)\nwith open(data_path1 + \"test_y_onehot.pkl\", \"rb\") as f:\n                test_y = pickle.load(f)\nwith open(data_path + \"train_filename.pkl\", \"rb\") as f:\n                file_name_train = pickle.load(f)\nwith open(data_path + \"test_filename.pkl\", \"rb\") as f:\n                file_name_test = pickle.load(f)\nwith open(data_path + \"val_filename.pkl\", \"rb\") as f:\n                file_name_val = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:12:32.984864Z","iopub.execute_input":"2022-05-02T19:12:32.985615Z","iopub.status.idle":"2022-05-02T19:12:33.266815Z","shell.execute_reply.started":"2022-05-02T19:12:32.985575Z","shell.execute_reply":"2022-05-02T19:12:33.266022Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class ChestXrayDataSet(Dataset):\n    def __init__(self, train_or_valid = \"train\", transform=None):\n\n        data_path = './'\n        self.train_or_valid = train_or_valid\n        if train_or_valid == \"train\":\n            self.X = np.uint8(np.load(data_path + \"train_X_small.npy\")*255*255)\n            with open(data_path + \"train_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            #sub_bool = (self.y.sum(axis=1)!=0)\n            #self.y = self.y[sub_bool,:]\n            #self.X = self.X[sub_bool,:]\n            with open( \"../input/pickles/train_y_onehot.pkl\", \"rb\") as f:\n                a = pickle.load(f)\n        elif train_or_valid == \"valid\":\n            self.X = np.uint8(np.load(data_path + \"valid_X_small.npy\")*255*255)\n            with open(data_path + \"val_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            with open(\"../input/pickles/val_y_onehot.pkl\", \"rb\") as f:\n                a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n        else:\n            self.X = np.uint8(np.load(data_path + \"test_X_small.npy\")*255*255)\n            with open(data_path + \"test_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            with open(\"../input/pickles/test_y_onehot.pkl\", \"rb\") as f:\n                a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n         \n        self.label_weight_pos = len(a.T[9])/a.T[9].sum(axis=0)\n        self.label_weight_neg = len(a.T[9])/(len(a.T[9])-a.T[9].sum(axis=0))\n        self.transform = transform\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index: the index of item \n        Returns:\n            image and its labels\n        \"\"\"\n        current_X = np.tile(self.X[index],3) \n        label = self.y[index]\n        label_inverse = 1- label\n        weight = np.add((label_inverse * self.label_weight_neg),(label * self.label_weight_pos))\n        if self.transform is not None:\n            image = self.transform(current_X)\n        return image, torch.from_numpy(np.asarray(label)).type(torch.FloatTensor), torch.from_numpy(np.asarray(weight)).type(torch.FloatTensor)\n        #return image, torch.from_numpy(np.asarray(label)).type(torch.FloatTensor)\n    def __len__(self):\n        return len(self.y)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:20:47.036964Z","iopub.execute_input":"2022-05-02T19:20:47.037244Z","iopub.status.idle":"2022-05-02T19:20:47.052347Z","shell.execute_reply.started":"2022-05-02T19:20:47.037214Z","shell.execute_reply":"2022-05-02T19:20:47.051597Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseNet121(nn.Module):\n    \"\"\"Model modified.\n    The architecture of our model is the same as standard DenseNet121\n    except the classifier layer which has an additional sigmoid function.\n    \"\"\"\n    def __init__(self, out_size):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n        num_ftrs = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n            nn.Linear(num_ftrs, out_size),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:12:51.481373Z","iopub.execute_input":"2022-05-02T19:12:51.482042Z","iopub.status.idle":"2022-05-02T19:12:51.488449Z","shell.execute_reply.started":"2022-05-02T19:12:51.481998Z","shell.execute_reply":"2022-05-02T19:12:51.487395Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"with open(\"../input/models/model_epoch_mass_withweights_epochs1.pkl\", \"rb\") as f:\n                model = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T05:56:07.512045Z","iopub.execute_input":"2022-05-01T05:56:07.512637Z","iopub.status.idle":"2022-05-01T05:56:07.649354Z","shell.execute_reply.started":"2022-05-01T05:56:07.512597Z","shell.execute_reply":"2022-05-01T05:56:07.648201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cudnn.benchmark = True\nN_CLASSES = 1\nBATCH_SIZE = 16\n\n\t# initialize and load the model\nmodel = DenseNet121(N_CLASSES).cuda()\nmodel = torch.nn.DataParallel(model).cuda()\noptimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:12:53.555150Z","iopub.execute_input":"2022-05-02T19:12:53.555788Z","iopub.status.idle":"2022-05-02T19:13:00.625604Z","shell.execute_reply.started":"2022-05-02T19:12:53.555736Z","shell.execute_reply":"2022-05-02T19:13:00.624875Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def train_util(index):\n    train_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_train[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        train_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_train)-1:\n            break\n    train_X = np.array(train_X)\n    np.save(os.path.join('./',\"train_X_small.npy\"), train_X)\n    train_y_ = train_y.T[9][index:i+1]\n    with open('./' + \"/train_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(train_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:13:00.627009Z","iopub.execute_input":"2022-05-02T19:13:00.627615Z","iopub.status.idle":"2022-05-02T19:13:00.634326Z","shell.execute_reply.started":"2022-05-02T19:13:00.627582Z","shell.execute_reply":"2022-05-02T19:13:00.633700Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def val_util(index):\n    val_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_val[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        val_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_val)-1:\n            break\n    val_X = np.array(val_X)\n    np.save(os.path.join('./',\"valid_X_small.npy\"), val_X)\n    val_y_ = val_y.T[9][index:i+1]\n    with open('./' + \"/val_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(val_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:13:03.643206Z","iopub.execute_input":"2022-05-02T19:13:03.643749Z","iopub.status.idle":"2022-05-02T19:13:03.651302Z","shell.execute_reply.started":"2022-05-02T19:13:03.643708Z","shell.execute_reply":"2022-05-02T19:13:03.650249Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def test_util(index):\n    test_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_test[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        test_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_test)-1:\n            break\n    print(len(test_X))\n    test_X = np.array(test_X)\n    np.save(os.path.join('./',\"test_X_small.npy\"), test_X)\n    test_y_ = test_y.T[9][index:i+1]\n    with open('./' + \"/test_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(test_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:13:08.152939Z","iopub.execute_input":"2022-05-02T19:13:08.153199Z","iopub.status.idle":"2022-05-02T19:13:08.166392Z","shell.execute_reply.started":"2022-05-02T19:13:08.153168Z","shell.execute_reply":"2022-05-02T19:13:08.165592Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train():\n    for k in range(0,len(file_name_train),1000):\n        train_util(k)\n        train_dataset = ChestXrayDataSet(train_or_valid=\"train\",\n                                        transform=transforms.Compose([\n                                            transforms.ToPILImage(),\n                                            transforms.RandomCrop(224),\n                                            transforms.RandomHorizontalFlip(),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                            ]))\n        augment_img = []\n        augment_label = []\n        augment_weight = []\n\n#         for i in range(4):\n        for j in range(len(train_dataset)):\n            single_img, single_label, single_weight = train_dataset[j]\n            #single_img, single_label = train_dataset[j]\n            augment_img.append(single_img)\n            augment_label.append(single_label)\n            augment_weight.append(single_weight)\n\n        # shuffe data\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = torch.stack(augment_img)[perm_index]\n        augment_label = torch.stack(augment_label)[perm_index]\n        augment_weight = torch.stack(augment_weight)[perm_index]\n\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = augment_img[perm_index]\n        augment_label = augment_label[perm_index]\n        augment_weight = augment_weight[perm_index]\n\n        optimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))\n        total_length = len(augment_img)\n        for index in range(0, total_length , BATCH_SIZE):\n            if index+BATCH_SIZE >= total_length:\n                break\n    # zero the parameter gradients\n            optimizer.zero_grad()\n            inputs_sub = augment_img[index:index+BATCH_SIZE]\n            labels_sub = augment_label[index:index+BATCH_SIZE]\n            weights_sub = augment_weight[index:index+BATCH_SIZE]\n            inputs_sub, labels_sub = Variable(inputs_sub.cuda()), Variable(labels_sub.cuda())\n            weights_sub = Variable(weights_sub.cuda())\n\n    # forward + backward + optimize\n            outputs = model(inputs_sub)\n            criterion = nn.BCELoss()\n            loss = criterion(outputs, torch.reshape(labels_sub,(16,1)))\n            loss.backward()\n            optimizer.step()\n        print(k)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:13:12.779007Z","iopub.execute_input":"2022-05-02T19:13:12.779516Z","iopub.status.idle":"2022-05-02T19:13:12.793066Z","shell.execute_reply.started":"2022-05-02T19:13:12.779454Z","shell.execute_reply":"2022-05-02T19:13:12.792355Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def val():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_val),1000):\n        val_util(k)\n        valid_dataset = ChestXrayDataSet(train_or_valid=\"valid\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        valid_loader = DataLoader(dataset=valid_dataset, batch_size=16, shuffle=False, num_workers=16)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target,weight) in enumerate(valid_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    \n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[9], AUROCs[i]))\n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:13:18.423361Z","iopub.execute_input":"2022-05-02T19:13:18.423909Z","iopub.status.idle":"2022-05-02T19:13:18.437350Z","shell.execute_reply.started":"2022-05-02T19:13:18.423868Z","shell.execute_reply":"2022-05-02T19:13:18.436586Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"len(file_name_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:13:20.531936Z","iopub.execute_input":"2022-05-02T19:13:20.532193Z","iopub.status.idle":"2022-05-02T19:13:20.539510Z","shell.execute_reply.started":"2022-05-02T19:13:20.532165Z","shell.execute_reply":"2022-05-02T19:13:20.538685Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_test),1000):\n        test_util(k)\n        test_dataset = ChestXrayDataSet(train_or_valid=\"test\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False, num_workers=2)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target,weight) in enumerate(test_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[9], AUROCs[i]))\n    \n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:13:25.299300Z","iopub.execute_input":"2022-05-02T19:13:25.299826Z","iopub.status.idle":"2022-05-02T19:13:25.313225Z","shell.execute_reply.started":"2022-05-02T19:13:25.299784Z","shell.execute_reply":"2022-05-02T19:13:25.312474Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def compute_AUCs(gt, pred):\n\t\n    AUROCs = []\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    gt_np = np.reshape(gt_np,(gt_np.shape[0],1))\n    print(gt_np.shape, pred_np.shape)\n    for i in range(N_CLASSES):\n        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return AUROCs\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:13:27.489329Z","iopub.execute_input":"2022-05-02T19:13:27.489869Z","iopub.status.idle":"2022-05-02T19:13:27.495098Z","shell.execute_reply.started":"2022-05-02T19:13:27.489829Z","shell.execute_reply":"2022-05-02T19:13:27.494310Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"epochs=1\nfor i in range(epochs):\n    train()\n    model.eval()\n    avg_roc = val()\n    torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(2)+'_'+str(avg_roc)+'.pkl')\n    model.train()\n  ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T21:50:29.694573Z","iopub.execute_input":"2022-05-02T21:50:29.695273Z","iopub.status.idle":"2022-05-02T23:58:10.899301Z","shell.execute_reply.started":"2022-05-02T21:50:29.695229Z","shell.execute_reply":"2022-05-02T23:58:10.898389Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(1)+'_'+str(AUROC_avg)+'.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:39:57.245726Z","iopub.execute_input":"2022-04-26T12:39:57.246301Z","iopub.status.idle":"2022-04-26T12:39:57.276397Z","shell.execute_reply.started":"2022-04-26T12:39:57.246261Z","shell.execute_reply":"2022-04-26T12:39:57.275428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-05-02T21:23:58.413900Z","iopub.execute_input":"2022-05-02T21:23:58.414207Z","iopub.status.idle":"2022-05-02T21:23:58.426306Z","shell.execute_reply.started":"2022-05-02T21:23:58.414167Z","shell.execute_reply":"2022-05-02T21:23:58.425410Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('./' + \"/model_epoch_mass_withweights_epochs2.pkl\",\"wb\") as f:\n    pickle.dump(model, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T00:02:11.881363Z","iopub.execute_input":"2022-05-03T00:02:11.881694Z","iopub.status.idle":"2022-05-03T00:02:11.993511Z","shell.execute_reply.started":"2022-05-03T00:02:11.881655Z","shell.execute_reply":"2022-05-03T00:02:11.992788Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(test())","metadata":{"execution":{"iopub.status.busy":"2022-05-03T00:02:28.460033Z","iopub.execute_input":"2022-05-03T00:02:28.460316Z","iopub.status.idle":"2022-05-03T00:02:53.091078Z","shell.execute_reply.started":"2022-05-03T00:02:28.460283Z","shell.execute_reply":"2022-05-03T00:02:53.090178Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"The average AUROC is 0.537","metadata":{},"execution_count":null,"outputs":[]}]}