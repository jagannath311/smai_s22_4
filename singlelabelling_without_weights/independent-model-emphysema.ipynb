{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport imageio\nfrom os import listdir\nimport skimage.transform\nimport pickle\nimport sys, os\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom collections import defaultdict\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom sklearn.metrics import roc_auc_score\nimport torch.optim as optim\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:31.412326Z","iopub.execute_input":"2022-05-02T14:31:31.413033Z","iopub.status.idle":"2022-05-02T14:31:34.396365Z","shell.execute_reply.started":"2022-05-02T14:31:31.412991Z","shell.execute_reply":"2022-05-02T14:31:34.395629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_entry_path = '../input/data/Data_Entry_2017.csv'\nmeta_data = pd.read_csv(data_entry_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_labels(pic_id):\n    try:\n        labels =  meta_data.loc[meta_data[\"Image Index\"]==pic_id,\"Finding Labels\"]\n        return labels.tolist()[0].split(\"|\")\n    except:\n        return []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y = []\nfile_name_test = []\ntrain_y = []\nfile_name_train = [] \nval_y = []\nfile_name_val = [] \ndirectory = ['../input/data/images_001/images','../input/data/images_002/images','../input/data/images_003/images','../input/data/images_004/images',\n            '../input/data/images_005/images','../input/data/images_006/images','../input/data/images_007/images','../input/data/images_008/images',\n            '../input/data/images_009/images','../input/data/images_010/images','../input/data/images_011/images','../input/data/images_012/images']\ny=0\nfor i in directory:\n    for filename in os.listdir(i):\n        image_path = os.path.join(i,filename)\n        if len(get_labels(filename))!=0 and y<420:\n            test_y.append(get_labels(filename))\n            file_name_test.append(image_path)\n            y=y+1\n        elif len(get_labels(filename))!=0 and y<100000:\n            train_y.append(get_labels(filename))\n            file_name_train.append(image_path)\n            y=y+1\n        else:\n            val_y.append(get_labels(filename))\n            file_name_val.append(image_path)\n            y=y+1\n        if y%3000==0:\n            print(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = MultiLabelBinarizer()\nencoder.fit(train_y+test_y+val_y)\ntrain_y_onehot = encoder.transform(train_y)\ntest_y_onehot = encoder.transform(test_y)\nval_y_onehot = encoder.transform(val_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.classes_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_weight_pos_train = (len(train_y_onehot)-(train_y_onehot).sum(axis=0))/len(train_y_onehot)\nlabel_weight_neg_train = (train_y_onehot.sum(axis=0))/len(train_y_onehot)\nlabel_weight_pos_test = (len(test_y_onehot)-(test_y_onehot).sum(axis=0))/len(test_y_onehot)\nlabel_weight_neg_test = (test_y_onehot.sum(axis=0))/len(test_y_onehot)\nlabel_weight_pos_val = (len(val_y_onehot)-(val_y_onehot).sum(axis=0))/len(val_y_onehot)\nlabel_weight_neg_val = (val_y_onehot.sum(axis=0))/len(val_y_onehot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./' + \"/train_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(train_y_onehot, f)\nwith open('./' + \"/test_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(test_y_onehot, f)\nwith open('./' + \"/val_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(val_y_onehot, f)\nwith open('./' + \"/train_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_train, f)\nwith open('./' + \"/test_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_test, f)\nwith open('./' + \"/val_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_val, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/pickles/'\ndata_path1 = '../input/pickles/'\nwith open(data_path1 + \"val_y_onehot.pkl\", \"rb\") as f:\n                val_y = pickle.load(f)\nwith open(data_path1 + \"train_y_onehot.pkl\", \"rb\") as f:\n                train_y = pickle.load(f)\nwith open(data_path1 + \"test_y_onehot.pkl\", \"rb\") as f:\n                test_y = pickle.load(f)\nwith open(data_path + \"train_filename.pkl\", \"rb\") as f:\n                file_name_train = pickle.load(f)\nwith open(data_path + \"test_filename.pkl\", \"rb\") as f:\n                file_name_test = pickle.load(f)\nwith open(data_path + \"val_filename.pkl\", \"rb\") as f:\n                file_name_val = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:34.398952Z","iopub.execute_input":"2022-05-02T14:31:34.399381Z","iopub.status.idle":"2022-05-02T14:31:34.643094Z","shell.execute_reply.started":"2022-05-02T14:31:34.399343Z","shell.execute_reply":"2022-05-02T14:31:34.642315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ChestXrayDataSet(Dataset):\n    def __init__(self, train_or_valid = \"train\", transform=None):\n\n        data_path = './'\n        self.train_or_valid = train_or_valid\n        if train_or_valid == \"train\":\n            self.X = np.uint8(np.load(data_path + \"train_X_small.npy\")*255*255)\n            with open(data_path + \"train_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            #sub_bool = (self.y.sum(axis=1)!=0)\n            #self.y = self.y[sub_bool,:]\n            #self.X = self.X[sub_bool,:]\n#             with open( \"../input/onehot/train_y_onehot.pkl\", \"rb\") as f:\n#                 a = pickle.load(f)\n        elif train_or_valid == \"valid\":\n            self.X = np.uint8(np.load(data_path + \"valid_X_small.npy\")*255*255)\n            with open(data_path + \"val_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n#             with open(\"../input/onehot/val_y_onehot.pkl\", \"rb\") as f:\n#                 a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n        else:\n            self.X = np.uint8(np.load(data_path + \"test_X_small.npy\")*255*255)\n            with open(data_path + \"test_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n#             with open(\"../input/onehot/test_y_onehot.pkl\", \"rb\") as f:\n#                 a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n         \n#         self.label_weight_pos = len(a)/a.sum(axis=0)\n#         self.label_weight_neg = len(a)/(len(a)-a.sum(axis=0))\n        self.transform = transform\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index: the index of item \n        Returns:\n            image and its labels\n        \"\"\"\n        current_X = np.tile(self.X[index],3) \n        label = self.y[index]\n        #label_inverse = 1- label\n        #weight = np.add((label_inverse * self.label_weight_neg),(label * self.label_weight_pos))\n        if self.transform is not None:\n            image = self.transform(current_X)\n        #return image, torch.from_numpy(label).type(torch.FloatTensor), torch.from_numpy(weight).type(torch.FloatTensor)\n        return image, torch.from_numpy(np.asarray(label)).type(torch.FloatTensor)\n    def __len__(self):\n        return len(self.y)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:34.644663Z","iopub.execute_input":"2022-05-02T14:31:34.64496Z","iopub.status.idle":"2022-05-02T14:31:34.658498Z","shell.execute_reply.started":"2022-05-02T14:31:34.644923Z","shell.execute_reply":"2022-05-02T14:31:34.657778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseNet121(nn.Module):\n    \"\"\"Model modified.\n    The architecture of our model is the same as standard DenseNet121\n    except the classifier layer which has an additional sigmoid function.\n    \"\"\"\n    def __init__(self, out_size):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n        num_ftrs = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n            nn.Linear(num_ftrs, out_size),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:34.661746Z","iopub.execute_input":"2022-05-02T14:31:34.66254Z","iopub.status.idle":"2022-05-02T14:31:34.672897Z","shell.execute_reply.started":"2022-05-02T14:31:34.661986Z","shell.execute_reply":"2022-05-02T14:31:34.672123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"../input/models2/model_epoch3_Emphysema.pkl\", \"rb\") as f:\n                model = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:34.674322Z","iopub.execute_input":"2022-05-02T14:31:34.674756Z","iopub.status.idle":"2022-05-02T14:31:38.228078Z","shell.execute_reply.started":"2022-05-02T14:31:34.674718Z","shell.execute_reply":"2022-05-02T14:31:38.227164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cudnn.benchmark = True\nN_CLASSES = 1\nBATCH_SIZE = 16\n\n\t# initialize and load the model\n# model = DenseNet121(N_CLASSES).cuda()\n# model = torch.nn.DataParallel(model).cuda()\noptimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.229494Z","iopub.execute_input":"2022-05-02T14:31:38.229759Z","iopub.status.idle":"2022-05-02T14:31:38.237433Z","shell.execute_reply.started":"2022-05-02T14:31:38.229697Z","shell.execute_reply":"2022-05-02T14:31:38.236621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_util(index):\n    train_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_train[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        train_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_train)-1:\n            break\n    train_X = np.array(train_X)\n    np.save(os.path.join('./',\"train_X_small.npy\"), train_X)\n    train_y_ = train_y.T[5][index:i+1]\n    with open('./' + \"/train_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(train_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.239153Z","iopub.execute_input":"2022-05-02T14:31:38.239414Z","iopub.status.idle":"2022-05-02T14:31:38.249504Z","shell.execute_reply.started":"2022-05-02T14:31:38.239379Z","shell.execute_reply":"2022-05-02T14:31:38.248751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_util(index):\n    val_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_val[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        val_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_val)-1:\n            break\n    val_X = np.array(val_X)\n    np.save(os.path.join('./',\"valid_X_small.npy\"), val_X)\n    val_y_ = val_y.T[5][index:i+1]\n    with open('./' + \"/val_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(val_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.25089Z","iopub.execute_input":"2022-05-02T14:31:38.251299Z","iopub.status.idle":"2022-05-02T14:31:38.260827Z","shell.execute_reply.started":"2022-05-02T14:31:38.251263Z","shell.execute_reply":"2022-05-02T14:31:38.260115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_util(index):\n    test_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_test[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        test_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_test)-1:\n            break\n    print(len(test_X))\n    test_X = np.array(test_X)\n    np.save(os.path.join('./',\"test_X_small.npy\"), test_X)\n    test_y_ = test_y.T[5][index:i+1]\n    with open('./' + \"/test_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(test_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.262325Z","iopub.execute_input":"2022-05-02T14:31:38.262605Z","iopub.status.idle":"2022-05-02T14:31:38.273455Z","shell.execute_reply.started":"2022-05-02T14:31:38.262568Z","shell.execute_reply":"2022-05-02T14:31:38.272651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    for k in range(0,len(file_name_train),1000):\n        train_util(k)\n        train_dataset = ChestXrayDataSet(train_or_valid=\"train\",\n                                        transform=transforms.Compose([\n                                            transforms.ToPILImage(),\n                                            transforms.RandomCrop(224),\n                                            transforms.RandomHorizontalFlip(),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                            ]))\n        augment_img = []\n        augment_label = []\n        #augment_weight = []\n\n#         for i in range(4):\n        for j in range(len(train_dataset)):\n                #single_img, single_label, single_weight = train_dataset[j]\n            single_img, single_label = train_dataset[j]\n            augment_img.append(single_img)\n            augment_label.append(single_label)\n                #augment_weight.append(single_weight)\n\n        # shuffe data\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = torch.stack(augment_img)[perm_index]\n        augment_label = torch.stack(augment_label)[perm_index]\n        #augment_weight = torch.stack(augment_weight)[perm_index]\n\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = augment_img[perm_index]\n        augment_label = augment_label[perm_index]\n        #augment_weight = augment_weight[perm_index]\n\n        optimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))\n        total_length = len(augment_img)\n        for index in range(0, total_length , BATCH_SIZE):\n            if index+BATCH_SIZE >= total_length:\n                break\n    # zero the parameter gradients\n            optimizer.zero_grad()\n            inputs_sub = augment_img[index:index+BATCH_SIZE]\n            labels_sub = augment_label[index:index+BATCH_SIZE]\n            #weights_sub = augment_weight[index:index+BATCH_SIZE]\n            inputs_sub, labels_sub = Variable(inputs_sub.cuda()), Variable(labels_sub.cuda())\n            #weights_sub = Variable(weights_sub.cuda())\n\n    # forward + backward + optimize\n            outputs = model(inputs_sub)\n            criterion = nn.BCELoss()\n            loss = criterion(outputs, torch.reshape(labels_sub,(16,1)))\n            loss.backward()\n            optimizer.step()\n        print(k)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.277571Z","iopub.execute_input":"2022-05-02T14:31:38.2778Z","iopub.status.idle":"2022-05-02T14:31:38.29213Z","shell.execute_reply.started":"2022-05-02T14:31:38.277773Z","shell.execute_reply":"2022-05-02T14:31:38.291469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_val),1000):\n        val_util(k)\n        valid_dataset = ChestXrayDataSet(train_or_valid=\"valid\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        valid_loader = DataLoader(dataset=valid_dataset, batch_size=16, shuffle=False, num_workers=16)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target) in enumerate(valid_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    \n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[5], AUROCs[i]))\n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.293414Z","iopub.execute_input":"2022-05-02T14:31:38.293662Z","iopub.status.idle":"2022-05-02T14:31:38.309369Z","shell.execute_reply.started":"2022-05-02T14:31:38.293628Z","shell.execute_reply":"2022-05-02T14:31:38.308578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(file_name_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.310694Z","iopub.execute_input":"2022-05-02T14:31:38.311028Z","iopub.status.idle":"2022-05-02T14:31:38.324305Z","shell.execute_reply.started":"2022-05-02T14:31:38.310985Z","shell.execute_reply":"2022-05-02T14:31:38.323372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_test),1000):\n        test_util(k)\n        test_dataset = ChestXrayDataSet(train_or_valid=\"test\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False, num_workers=2)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target) in enumerate(test_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[5], AUROCs[i]))\n    \n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.326178Z","iopub.execute_input":"2022-05-02T14:31:38.326598Z","iopub.status.idle":"2022-05-02T14:31:38.341529Z","shell.execute_reply.started":"2022-05-02T14:31:38.326561Z","shell.execute_reply":"2022-05-02T14:31:38.340683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_AUCs(gt, pred):\n\t\n    AUROCs = []\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    gt_np = np.reshape(gt_np,(gt_np.shape[0],1))\n    print(gt_np.shape, pred_np.shape)\n    for i in range(N_CLASSES):\n        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return AUROCs\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.343237Z","iopub.execute_input":"2022-05-02T14:31:38.343826Z","iopub.status.idle":"2022-05-02T14:31:38.354161Z","shell.execute_reply.started":"2022-05-02T14:31:38.343765Z","shell.execute_reply":"2022-05-02T14:31:38.353264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=1\nfor i in range(epochs):\n    train()\n    model.eval()\n    avg_roc = val()\n#     torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(2)+'_'+str(avg_roc)+'.pkl')\n    model.train()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:31:38.356802Z","iopub.execute_input":"2022-05-02T14:31:38.357323Z","iopub.status.idle":"2022-05-02T16:33:20.485833Z","shell.execute_reply.started":"2022-05-02T14:31:38.35727Z","shell.execute_reply":"2022-05-02T16:33:20.484284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(1)+'_'+str(AUROC_avg)+'.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:33:20.487419Z","iopub.execute_input":"2022-05-02T16:33:20.487718Z","iopub.status.idle":"2022-05-02T16:33:20.492044Z","shell.execute_reply.started":"2022-05-02T16:33:20.487663Z","shell.execute_reply":"2022-05-02T16:33:20.491321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:33:20.493653Z","iopub.execute_input":"2022-05-02T16:33:20.494523Z","iopub.status.idle":"2022-05-02T16:33:20.514255Z","shell.execute_reply.started":"2022-05-02T16:33:20.494485Z","shell.execute_reply":"2022-05-02T16:33:20.513586Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('./' + \"/model_epoch4_Emphysema.pkl\",\"wb\") as f:\n    pickle.dump(model, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:33:20.51723Z","iopub.execute_input":"2022-05-02T16:33:20.517896Z","iopub.status.idle":"2022-05-02T16:33:20.628169Z","shell.execute_reply.started":"2022-05-02T16:33:20.517855Z","shell.execute_reply":"2022-05-02T16:33:20.627409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test())","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:33:20.62964Z","iopub.execute_input":"2022-05-02T16:33:20.629914Z","iopub.status.idle":"2022-05-02T16:33:47.834963Z","shell.execute_reply.started":"2022-05-02T16:33:20.62988Z","shell.execute_reply":"2022-05-02T16:33:47.833377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}