{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport imageio\nfrom os import listdir\nimport skimage.transform\nimport pickle\nimport sys, os\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom collections import defaultdict\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom sklearn.metrics import roc_auc_score\nimport torch.optim as optim\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:26:44.314878Z","iopub.execute_input":"2022-05-02T11:26:44.315568Z","iopub.status.idle":"2022-05-02T11:26:44.32177Z","shell.execute_reply.started":"2022-05-02T11:26:44.315506Z","shell.execute_reply":"2022-05-02T11:26:44.321078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_entry_path = '../input/data/Data_Entry_2017.csv'\nmeta_data = pd.read_csv(data_entry_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:26:45.692154Z","iopub.execute_input":"2022-05-02T11:26:45.692837Z","iopub.status.idle":"2022-05-02T11:26:45.864332Z","shell.execute_reply.started":"2022-05-02T11:26:45.6928Z","shell.execute_reply":"2022-05-02T11:26:45.863591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_labels(pic_id):\n    try:\n        labels =  meta_data.loc[meta_data[\"Image Index\"]==pic_id,\"Finding Labels\"]\n        return labels.tolist()[0].split(\"|\")\n    except:\n        return []","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:26:47.074104Z","iopub.execute_input":"2022-05-02T11:26:47.074709Z","iopub.status.idle":"2022-05-02T11:26:47.08174Z","shell.execute_reply.started":"2022-05-02T11:26:47.07467Z","shell.execute_reply":"2022-05-02T11:26:47.081003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y = []\nfile_name_test = []\ntrain_y = []\nfile_name_train = [] \nval_y = []\nfile_name_val = [] \ndirectory = ['../input/data/images_001/images','../input/data/images_002/images','../input/data/images_003/images','../input/data/images_004/images',\n            '../input/data/images_005/images','../input/data/images_006/images','../input/data/images_007/images','../input/data/images_008/images',\n            '../input/data/images_009/images','../input/data/images_010/images','../input/data/images_011/images','../input/data/images_012/images']\ny=0\nfor i in directory:\n    for filename in os.listdir(i):\n        image_path = os.path.join(i,filename)\n        if len(get_labels(filename))!=0 and y<420:\n            test_y.append(get_labels(filename))\n            file_name_test.append(image_path)\n            y=y+1\n        elif len(get_labels(filename))!=0 and y<100000:\n            train_y.append(get_labels(filename))\n            file_name_train.append(image_path)\n            y=y+1\n        else:\n            val_y.append(get_labels(filename))\n            file_name_val.append(image_path)\n            y=y+1\n        if y%3000==0:\n            print(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = MultiLabelBinarizer()\nencoder.fit(train_y+test_y+val_y)\ntrain_y_onehot = encoder.transform(train_y)\ntest_y_onehot = encoder.transform(test_y)\nval_y_onehot = encoder.transform(val_y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.classes_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_weight_pos_train = (len(train_y_onehot)-(train_y_onehot).sum(axis=0))/len(train_y_onehot)\nlabel_weight_neg_train = (train_y_onehot.sum(axis=0))/len(train_y_onehot)\nlabel_weight_pos_test = (len(test_y_onehot)-(test_y_onehot).sum(axis=0))/len(test_y_onehot)\nlabel_weight_neg_test = (test_y_onehot.sum(axis=0))/len(test_y_onehot)\nlabel_weight_pos_val = (len(val_y_onehot)-(val_y_onehot).sum(axis=0))/len(val_y_onehot)\nlabel_weight_neg_val = (val_y_onehot.sum(axis=0))/len(val_y_onehot)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./' + \"/train_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(train_y_onehot, f)\nwith open('./' + \"/test_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(test_y_onehot, f)\nwith open('./' + \"/val_y_onehot.pkl\",\"wb\") as f:\n    pickle.dump(val_y_onehot, f)\nwith open('./' + \"/train_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_train, f)\nwith open('./' + \"/test_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_test, f)\nwith open('./' + \"/val_filename.pkl\",\"wb\") as f:\n    pickle.dump(file_name_val, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/dataset/'\ndata_path1 = '../input/dataset/'\nwith open(data_path1 + \"val_y_onehot.pkl\", \"rb\") as f:\n                val_y = pickle.load(f)\nwith open(data_path1 + \"train_y_onehot.pkl\", \"rb\") as f:\n                train_y = pickle.load(f)\nwith open(data_path1 + \"test_y_onehot.pkl\", \"rb\") as f:\n                test_y = pickle.load(f)\nwith open(data_path + \"train_filename.pkl\", \"rb\") as f:\n                file_name_train = pickle.load(f)\nwith open(data_path + \"test_filename.pkl\", \"rb\") as f:\n                file_name_test = pickle.load(f)\nwith open(data_path + \"val_filename.pkl\", \"rb\") as f:\n                file_name_val = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:26:51.88945Z","iopub.execute_input":"2022-05-02T11:26:51.890246Z","iopub.status.idle":"2022-05-02T11:26:51.945016Z","shell.execute_reply.started":"2022-05-02T11:26:51.890201Z","shell.execute_reply":"2022-05-02T11:26:51.944289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ChestXrayDataSet(Dataset):\n    def __init__(self, train_or_valid = \"train\", transform=None):\n\n        data_path = './'\n        self.train_or_valid = train_or_valid\n        if train_or_valid == \"train\":\n            self.X = np.uint8(np.load(data_path + \"train_X_small.npy\")*255*255)\n            with open(data_path + \"train_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n            #sub_bool = (self.y.sum(axis=1)!=0)\n            #self.y = self.y[sub_bool,:]\n            #self.X = self.X[sub_bool,:]\n#             with open( \"../input/onehot/train_y_onehot.pkl\", \"rb\") as f:\n#                 a = pickle.load(f)\n        elif train_or_valid == \"valid\":\n            self.X = np.uint8(np.load(data_path + \"valid_X_small.npy\")*255*255)\n            with open(data_path + \"val_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n#             with open(\"../input/onehot/val_y_onehot.pkl\", \"rb\") as f:\n#                 a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n        else:\n            self.X = np.uint8(np.load(data_path + \"test_X_small.npy\")*255*255)\n            with open(data_path + \"test_y_onehot_.pkl\", \"rb\") as f:\n                self.y = pickle.load(f)\n#             with open(\"../input/onehot/test_y_onehot.pkl\", \"rb\") as f:\n#                 a = pickle.load(f)\n#         self.label_weight_pos = label_weight_po\n#         self.label_weight_neg = label_weight_ne\n         \n#         self.label_weight_pos = len(a)/a.sum(axis=0)\n#         self.label_weight_neg = len(a)/(len(a)-a.sum(axis=0))\n        self.transform = transform\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index: the index of item \n        Returns:\n            image and its labels\n        \"\"\"\n        current_X = np.tile(self.X[index],3) \n        label = self.y[index]\n        #label_inverse = 1- label\n        #weight = np.add((label_inverse * self.label_weight_neg),(label * self.label_weight_pos))\n        if self.transform is not None:\n            image = self.transform(current_X)\n        #return image, torch.from_numpy(label).type(torch.FloatTensor), torch.from_numpy(weight).type(torch.FloatTensor)\n        return image, torch.from_numpy(np.asarray(label)).type(torch.FloatTensor)\n    def __len__(self):\n        return len(self.y)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:26:52.430064Z","iopub.execute_input":"2022-05-02T11:26:52.430643Z","iopub.status.idle":"2022-05-02T11:26:52.445818Z","shell.execute_reply.started":"2022-05-02T11:26:52.430592Z","shell.execute_reply":"2022-05-02T11:26:52.444945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseNet121(nn.Module):\n    \"\"\"Model modified.\n    The architecture of our model is the same as standard DenseNet121\n    except the classifier layer which has an additional sigmoid function.\n    \"\"\"\n    def __init__(self, out_size):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n        num_ftrs = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n            nn.Linear(num_ftrs, out_size),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:26:53.237436Z","iopub.execute_input":"2022-05-02T11:26:53.238121Z","iopub.status.idle":"2022-05-02T11:26:53.245044Z","shell.execute_reply.started":"2022-05-02T11:26:53.238082Z","shell.execute_reply":"2022-05-02T11:26:53.244218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"../input/models/model_epoch_Pnuemonia_epoch2.pkl\", \"rb\") as f:\n                model = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:27:52.154884Z","iopub.execute_input":"2022-05-02T11:27:52.155138Z","iopub.status.idle":"2022-05-02T11:27:52.27942Z","shell.execute_reply.started":"2022-05-02T11:27:52.15511Z","shell.execute_reply":"2022-05-02T11:27:52.27872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cudnn.benchmark = True\nN_CLASSES = 1\nBATCH_SIZE = 16\n\n\t# initialize and load the model\nmodel = DenseNet121(N_CLASSES).cuda()\nmodel = torch.nn.DataParallel(model).cuda()\noptimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:26:54.236043Z","iopub.execute_input":"2022-05-02T11:26:54.2366Z","iopub.status.idle":"2022-05-02T11:27:01.503139Z","shell.execute_reply.started":"2022-05-02T11:26:54.23656Z","shell.execute_reply":"2022-05-02T11:27:01.502353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_util(index):\n    train_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_train[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        train_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_train)-1:\n            break\n    train_X = np.array(train_X)\n    np.save(os.path.join('./',\"train_X_small.npy\"), train_X)\n    train_y_ = train_y.T[13][index:i+1]\n    with open('./' + \"/train_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(train_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:27:57.584859Z","iopub.execute_input":"2022-05-02T11:27:57.585108Z","iopub.status.idle":"2022-05-02T11:27:57.592276Z","shell.execute_reply.started":"2022-05-02T11:27:57.58508Z","shell.execute_reply":"2022-05-02T11:27:57.591593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_util(index):\n    val_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_val[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        val_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_val)-1:\n            break\n    val_X = np.array(val_X)\n    np.save(os.path.join('./',\"valid_X_small.npy\"), val_X)\n    val_y_ = val_y.T[13][index:i+1]\n    with open('./' + \"/val_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(val_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:27:58.160315Z","iopub.execute_input":"2022-05-02T11:27:58.160819Z","iopub.status.idle":"2022-05-02T11:27:58.168559Z","shell.execute_reply.started":"2022-05-02T11:27:58.160785Z","shell.execute_reply":"2022-05-02T11:27:58.167514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_util(index):\n    test_X=[]\n    for i in range(index,index+1000):\n        image_path = file_name_test[i]    \n        img = imageio.imread(image_path)\n        if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n            img = img[:,:,0]\n        img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n        test_X.append((np.array(img_resized)/255).reshape(256,256,1))\n        if i==len(file_name_test)-1:\n            break\n    print(len(test_X))\n    test_X = np.array(test_X)\n    np.save(os.path.join('./',\"test_X_small.npy\"), test_X)\n    test_y_ = test_y.T[13][index:i+1]\n    with open('./' + \"/test_y_onehot_.pkl\",\"wb\") as f:\n        pickle.dump(test_y_, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:27:58.52882Z","iopub.execute_input":"2022-05-02T11:27:58.529561Z","iopub.status.idle":"2022-05-02T11:27:58.537376Z","shell.execute_reply.started":"2022-05-02T11:27:58.529493Z","shell.execute_reply":"2022-05-02T11:27:58.5367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    for k in range(0,len(file_name_train),1000):\n        train_util(k)\n        train_dataset = ChestXrayDataSet(train_or_valid=\"train\",\n                                        transform=transforms.Compose([\n                                            transforms.ToPILImage(),\n                                            transforms.RandomCrop(224),\n                                            transforms.RandomHorizontalFlip(),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                            ]))\n        augment_img = []\n        augment_label = []\n        #augment_weight = []\n\n#         for i in range(4):\n        for j in range(len(train_dataset)):\n                #single_img, single_label, single_weight = train_dataset[j]\n            single_img, single_label = train_dataset[j]\n            augment_img.append(single_img)\n            augment_label.append(single_label)\n                #augment_weight.append(single_weight)\n\n        # shuffe data\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = torch.stack(augment_img)[perm_index]\n        augment_label = torch.stack(augment_label)[perm_index]\n        #augment_weight = torch.stack(augment_weight)[perm_index]\n\n        perm_index = torch.randperm(len(augment_label))\n        augment_img = augment_img[perm_index]\n        augment_label = augment_label[perm_index]\n        #augment_weight = augment_weight[perm_index]\n\n        optimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))\n        total_length = len(augment_img)\n        for index in range(0, total_length , BATCH_SIZE):\n            if index+BATCH_SIZE >= total_length:\n                break\n    # zero the parameter gradients\n            optimizer.zero_grad()\n            inputs_sub = augment_img[index:index+BATCH_SIZE]\n            labels_sub = augment_label[index:index+BATCH_SIZE]\n            #weights_sub = augment_weight[index:index+BATCH_SIZE]\n            inputs_sub, labels_sub = Variable(inputs_sub.cuda()), Variable(labels_sub.cuda())\n            #weights_sub = Variable(weights_sub.cuda())\n\n    # forward + backward + optimize\n            outputs = model(inputs_sub)\n            criterion = nn.BCELoss()\n            loss = criterion(outputs, torch.reshape(labels_sub,(16,1)))\n            loss.backward()\n            optimizer.step()\n        print(k)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:27:58.860815Z","iopub.execute_input":"2022-05-02T11:27:58.861345Z","iopub.status.idle":"2022-05-02T11:27:58.87408Z","shell.execute_reply.started":"2022-05-02T11:27:58.861314Z","shell.execute_reply":"2022-05-02T11:27:58.873397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_val),1000):\n        val_util(k)\n        valid_dataset = ChestXrayDataSet(train_or_valid=\"valid\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        valid_loader = DataLoader(dataset=valid_dataset, batch_size=16, shuffle=False, num_workers=16)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target) in enumerate(valid_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    \n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))\n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:27:59.193252Z","iopub.execute_input":"2022-05-02T11:27:59.193825Z","iopub.status.idle":"2022-05-02T11:27:59.205655Z","shell.execute_reply.started":"2022-05-02T11:27:59.193785Z","shell.execute_reply":"2022-05-02T11:27:59.204886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(file_name_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:27:59.612059Z","iopub.execute_input":"2022-05-02T11:27:59.612795Z","iopub.status.idle":"2022-05-02T11:27:59.619679Z","shell.execute_reply.started":"2022-05-02T11:27:59.61275Z","shell.execute_reply":"2022-05-02T11:27:59.618872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test():\n    gt_all = torch.FloatTensor()\n    gt_all = gt_all.cuda()\n    pred_all = torch.FloatTensor()\n    pred_all = pred_all.cuda()\n    for k in range(0,len(file_name_test),1000):\n        test_util(k)\n        test_dataset = ChestXrayDataSet(train_or_valid=\"test\",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n        test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False, num_workers=2)\n        gt = torch.FloatTensor()\n        gt = gt.cuda()\n        pred = torch.FloatTensor()\n        pred = pred.cuda()\n        for i, (inp, target) in enumerate(test_loader):\n            target = target.cuda()\n            gt = torch.cat((gt, target), 0)\n            gt_all = torch.cat((gt_all, target), 0)\n            #     bs, n_crops, c, h, w = inp.size()\n            input_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n            output = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n            pred = torch.cat((pred, output.data), 0)\n            pred_all = torch.cat((pred_all, output.data), 0)\n        print(k)\n    CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n       'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration',\n       'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia',\n       'Pneumothorax']\n    AUROCs = compute_AUCs(gt_all, pred_all)\n    AUROC_avg = np.array(AUROCs).mean()\n    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n    for i in range(N_CLASSES):\n        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))\n    \n    return AUROC_avg","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:28:01.520323Z","iopub.execute_input":"2022-05-02T11:28:01.520853Z","iopub.status.idle":"2022-05-02T11:28:01.531938Z","shell.execute_reply.started":"2022-05-02T11:28:01.52082Z","shell.execute_reply":"2022-05-02T11:28:01.531282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_AUCs(gt, pred):\n\t\n    AUROCs = []\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    gt_np = np.reshape(gt_np,(gt_np.shape[0],1))\n    print(gt_np.shape, pred_np.shape)\n    for i in range(N_CLASSES):\n        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return AUROCs\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:28:02.145793Z","iopub.execute_input":"2022-05-02T11:28:02.146311Z","iopub.status.idle":"2022-05-02T11:28:02.15158Z","shell.execute_reply.started":"2022-05-02T11:28:02.146272Z","shell.execute_reply":"2022-05-02T11:28:02.150745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=2\nfor i in range(epochs):\n    train()\n    model.eval()\n    avg_roc = val()\n    torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(2)+'_'+str(avg_roc)+'.pkl')\n    model.train()\n  ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T11:28:04.483304Z","iopub.execute_input":"2022-05-02T11:28:04.483836Z","iopub.status.idle":"2022-05-02T16:08:52.86629Z","shell.execute_reply.started":"2022-05-02T11:28:04.4838Z","shell.execute_reply":"2022-05-02T16:08:52.864444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),'DenseNet121_aug4_pretrain_noWeight_'+str(1)+'_'+str(AUROC_avg)+'.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./' + \"/model_epoch_Pnuemonia_epoch4.pkl\",\"wb\") as f:\n    pickle.dump(model, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:08:52.868707Z","iopub.execute_input":"2022-05-02T16:08:52.869003Z","iopub.status.idle":"2022-05-02T16:08:52.977706Z","shell.execute_reply.started":"2022-05-02T16:08:52.868962Z","shell.execute_reply":"2022-05-02T16:08:52.977035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:13:54.792919Z","iopub.execute_input":"2022-05-02T16:13:54.79336Z","iopub.status.idle":"2022-05-02T16:14:22.351776Z","shell.execute_reply.started":"2022-05-02T16:13:54.793318Z","shell.execute_reply":"2022-05-02T16:14:22.351033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}